{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARGOS - Gerador Autom√°tico de Data Schemas\n",
    "\n",
    "Este notebook gera automaticamente os arquivos de schema para todas as tabelas do projeto ARGOS.\n",
    "\n",
    "## O que ser√° gerado:\n",
    "\n",
    "Para cada tabela:\n",
    "- `DESCRIBE FORMATTED` - estrutura completa da tabela\n",
    "- `SELECT * FROM ... LIMIT 10` - amostra de dados\n",
    "\n",
    "## Tabelas processadas:\n",
    "\n",
    "### Originais (4 tabelas)\n",
    "- nfce.nfce\n",
    "- niat.argos_cnpj\n",
    "- niat.tabela_niat\n",
    "- usr_sat_ods.vw_ods_contrib\n",
    "\n",
    "### Intermedi√°rias (4 tabelas)\n",
    "- niat.argos_nfce_base_extraida\n",
    "- niat.argos_nfce_periodo_base\n",
    "- niat.argos_medias_historicas_produto\n",
    "- niat.argos_mudanca_comportamento\n",
    "\n",
    "### Views (1 tabela)\n",
    "- niat.argos_vw_evolucao_nfce ‚≠ê (mais importante - usada em todo o Streamlit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Importar Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "print(\"‚úÖ Bibliotecas importadas com sucesso\")\n",
    "print(f\"üìÖ Data/Hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configurar Lista de Tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista completa de tabelas a serem documentadas\n",
    "TABELAS = {\n",
    "    'ORIGINAIS': [\n",
    "        'nfce.nfce',\n",
    "        'niat.argos_cnpj',\n",
    "        'niat.tabela_niat',\n",
    "        'usr_sat_ods.vw_ods_contrib'\n",
    "    ],\n",
    "    'INTERMEDIARIAS': [\n",
    "        'niat.argos_nfce_base_extraida',\n",
    "        'niat.argos_nfce_periodo_base',\n",
    "        'niat.argos_medias_historicas_produto',\n",
    "        'niat.argos_mudanca_comportamento'\n",
    "    ],\n",
    "    'VIEWS': [\n",
    "        'niat.argos_vw_evolucao_nfce'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Diret√≥rio de sa√≠da\n",
    "OUTPUT_DIR = './data-schemas'\n",
    "\n",
    "# Contagem total\n",
    "total = sum(len(v) for v in TABELAS.values())\n",
    "print(f\"üìä Total de tabelas configuradas: {total}\")\n",
    "for categoria, lista in TABELAS.items():\n",
    "    print(f\"   - {categoria}: {len(lista)} tabelas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Criar Diret√≥rio de Sa√≠da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar diret√≥rio se n√£o existir\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "    print(f\"‚úÖ Diret√≥rio criado: {OUTPUT_DIR}\")\n",
    "else:\n",
    "    print(f\"‚ÑπÔ∏è  Diret√≥rio j√° existe: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fun√ß√µes Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_nome_arquivo(tabela_completa):\n",
    "    \"\"\"Converte nome da tabela em nome de arquivo\"\"\"\n",
    "    nome = tabela_completa.split('.')[-1]\n",
    "    return f\"{nome}_schema.txt\"\n",
    "\n",
    "def formatar_header(titulo, char='='):\n",
    "    \"\"\"Formata header para os arquivos\"\"\"\n",
    "    linha = char * 80\n",
    "    return f\"\\n{linha}\\n{titulo.center(80)}\\n{linha}\\n\"\n",
    "\n",
    "def salvar_schema(tabela, describe_df, sample_df, categoria):\n",
    "    \"\"\"Salva schema completo em arquivo\"\"\"\n",
    "    nome_arquivo = obter_nome_arquivo(tabela)\n",
    "    caminho_completo = os.path.join(OUTPUT_DIR, nome_arquivo)\n",
    "\n",
    "    with open(caminho_completo, 'w', encoding='utf-8') as f:\n",
    "        # Header do arquivo\n",
    "        f.write(formatar_header(f'DATA SCHEMA - {tabela}'))\n",
    "        f.write(f\"\\nCategoria: {categoria}\\n\")\n",
    "        f.write(f\"Gerado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Tabela: {tabela}\\n\")\n",
    "\n",
    "        # DESCRIBE FORMATTED\n",
    "        f.write(formatar_header('DESCRIBE FORMATTED', '-'))\n",
    "        f.write(\"\\n```sql\\n\")\n",
    "        f.write(f\"DESCRIBE FORMATTED {tabela};\\n\")\n",
    "        f.write(\"```\\n\\n\")\n",
    "        \n",
    "        describe_str = describe_df.toPandas().to_string(index=False, max_rows=None)\n",
    "        f.write(describe_str)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "        # SELECT LIMIT 10\n",
    "        f.write(formatar_header('SELECT * FROM ... LIMIT 10', '-'))\n",
    "        f.write(\"\\n```sql\\n\")\n",
    "        f.write(f\"SELECT * FROM {tabela} LIMIT 10;\\n\")\n",
    "        f.write(\"```\\n\\n\")\n",
    "        \n",
    "        sample_str = sample_df.toPandas().to_string(index=False, max_rows=None)\n",
    "        f.write(sample_str)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "        # Footer\n",
    "        f.write(formatar_header('FIM DO SCHEMA', '='))\n",
    "\n",
    "    return caminho_completo\n",
    "\n",
    "print(\"‚úÖ Fun√ß√µes auxiliares definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fun√ß√£o de Extra√ß√£o de Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_schema_tabela(tabela, categoria):\n",
    "    \"\"\"\n",
    "    Extrai schema e dados de exemplo de uma tabela\n",
    "    \n",
    "    Args:\n",
    "        tabela: Nome completo da tabela (schema.tabela)\n",
    "        categoria: Categoria da tabela\n",
    "        \n",
    "    Returns:\n",
    "        True se sucesso, False se erro\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processando: {tabela} ({categoria})\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    try:\n",
    "        # 1. DESCRIBE FORMATTED\n",
    "        print(f\"‚è≥ Executando DESCRIBE FORMATTED {tabela}...\")\n",
    "        describe_query = f\"DESCRIBE FORMATTED {tabela}\"\n",
    "        describe_df = spark.sql(describe_query)\n",
    "        num_linhas = describe_df.count()\n",
    "        print(f\"‚úÖ DESCRIBE obtido - {num_linhas} linhas\")\n",
    "\n",
    "        # 2. SELECT LIMIT 10\n",
    "        print(f\"‚è≥ Executando SELECT * FROM {tabela} LIMIT 10...\")\n",
    "        sample_query = f\"SELECT * FROM {tabela} LIMIT 10\"\n",
    "        sample_df = spark.sql(sample_query)\n",
    "        num_colunas = len(sample_df.columns)\n",
    "        num_registros = sample_df.count()\n",
    "        print(f\"‚úÖ Sample obtido - {num_colunas} colunas, {num_registros} registros\")\n",
    "\n",
    "        # 3. Salvar em arquivo\n",
    "        print(f\"üíæ Salvando schema em arquivo...\")\n",
    "        caminho = salvar_schema(tabela, describe_df, sample_df, categoria)\n",
    "        print(f\"‚úÖ Schema salvo: {caminho}\")\n",
    "        \n",
    "        # 4. Exibir preview\n",
    "        print(f\"\\nüìã Preview da estrutura:\")\n",
    "        sample_df.printSchema()\n",
    "        \n",
    "        print(f\"\\nüìä Preview dos dados (primeiras 3 linhas):\")\n",
    "        sample_df.show(3, truncate=True, vertical=False)\n",
    "\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERRO ao processar {tabela}: {str(e)}\")\n",
    "        \n",
    "        # Salvar erro em arquivo\n",
    "        nome_arquivo = obter_nome_arquivo(tabela)\n",
    "        caminho_erro = os.path.join(OUTPUT_DIR, f\"ERRO_{nome_arquivo}\")\n",
    "        \n",
    "        with open(caminho_erro, 'w', encoding='utf-8') as f:\n",
    "            f.write(formatar_header(f'ERRO - {tabela}'))\n",
    "            f.write(f\"\\nCategoria: {categoria}\\n\")\n",
    "            f.write(f\"Erro em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(f\"\\nMensagem de erro:\\n{str(e)}\\n\")\n",
    "        \n",
    "        print(f\"‚ö†Ô∏è  Erro salvo em: {caminho_erro}\")\n",
    "        return False\n",
    "\n",
    "print(\"‚úÖ Fun√ß√£o de extra√ß√£o definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. üöÄ EXECUTAR GERA√á√ÉO DE SCHEMAS\n",
    "\n",
    "‚ö†Ô∏è **ATEN√á√ÉO**: Execute a c√©lula abaixo para processar TODAS as tabelas de uma vez.\n",
    "\n",
    "Ou execute as c√©lulas seguintes para processar por categoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OP√á√ÉO 1: EXECUTAR TODAS AS TABELAS DE UMA VEZ\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ARGOS - GERADOR AUTOM√ÅTICO DE DATA SCHEMAS\".center(80))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Contadores\n",
    "total_tabelas = sum(len(tabelas) for tabelas in TABELAS.values())\n",
    "processadas = 0\n",
    "sucesso = 0\n",
    "falhas = 0\n",
    "\n",
    "# Processar cada categoria\n",
    "for categoria, lista_tabelas in TABELAS.items():\n",
    "    print(f\"\\n{'#'*80}\")\n",
    "    print(f\"CATEGORIA: {categoria}\".center(80))\n",
    "    print(f\"{'#'*80}\")\n",
    "    \n",
    "    for tabela in lista_tabelas:\n",
    "        processadas += 1\n",
    "        resultado = extrair_schema_tabela(tabela, categoria)\n",
    "        \n",
    "        if resultado:\n",
    "            sucesso += 1\n",
    "        else:\n",
    "            falhas += 1\n",
    "        \n",
    "        print(f\"\\nüìä Progresso: {processadas}/{total_tabelas} tabelas processadas\")\n",
    "\n",
    "# Resumo final\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMO FINAL\".center(80))\n",
    "print(\"=\"*80)\n",
    "print(f\"‚úÖ Total de tabelas: {total_tabelas}\")\n",
    "print(f\"‚úÖ Processadas com sucesso: {sucesso}\")\n",
    "print(f\"‚ùå Falhas: {falhas}\")\n",
    "print(f\"üìÅ Arquivos salvos em: {OUTPUT_DIR}\")\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. OP√á√ÉO 2: Executar por Categoria (Opcional)\n",
    "\n",
    "Se preferir processar uma categoria por vez, execute as c√©lulas abaixo individualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processar apenas TABELAS ORIGINAIS\n",
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"PROCESSANDO: TABELAS ORIGINAIS\".center(80))\n",
    "print(\"#\"*80)\n",
    "\n",
    "for tabela in TABELAS['ORIGINAIS']:\n",
    "    extrair_schema_tabela(tabela, 'ORIGINAIS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processar apenas TABELAS INTERMEDI√ÅRIAS\n",
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"PROCESSANDO: TABELAS INTERMEDI√ÅRIAS\".center(80))\n",
    "print(\"#\"*80)\n",
    "\n",
    "for tabela in TABELAS['INTERMEDIARIAS']:\n",
    "    extrair_schema_tabela(tabela, 'INTERMEDIARIAS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processar apenas VIEWS\n",
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"PROCESSANDO: VIEWS\".center(80))\n",
    "print(\"#\"*80)\n",
    "\n",
    "for tabela in TABELAS['VIEWS']:\n",
    "    extrair_schema_tabela(tabela, 'VIEWS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. OP√á√ÉO 3: Processar Tabela Individual (Opcional)\n",
    "\n",
    "Para processar uma tabela espec√≠fica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processar apenas uma tabela espec√≠fica\n",
    "# Altere o nome da tabela conforme necess√°rio\n",
    "\n",
    "tabela_especifica = 'niat.argos_vw_evolucao_nfce'\n",
    "categoria_especifica = 'VIEWS'\n",
    "\n",
    "extrair_schema_tabela(tabela_especifica, categoria_especifica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Gerar √çndice README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar arquivo README.md com √≠ndice de todos os schemas\n",
    "\n",
    "indice_path = os.path.join(OUTPUT_DIR, 'README.md')\n",
    "\n",
    "with open(indice_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"# ARGOS - Data Schemas\\n\\n\")\n",
    "    f.write(f\"Gerado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "    f.write(\"---\\n\\n\")\n",
    "\n",
    "    f.write(\"## Estrutura de Dados\\n\\n\")\n",
    "    f.write(\"Este diret√≥rio cont√©m os schemas completos de todas as tabelas utilizadas no projeto ARGOS.\\n\\n\")\n",
    "\n",
    "    # Listar por categoria\n",
    "    for categoria, lista_tabelas in TABELAS.items():\n",
    "        f.write(f\"### {categoria}\\n\\n\")\n",
    "        \n",
    "        for tabela in lista_tabelas:\n",
    "            nome_arquivo = obter_nome_arquivo(tabela)\n",
    "            f.write(f\"- **{tabela}** ‚Üí [`{nome_arquivo}`](./{nome_arquivo})\\n\")\n",
    "        \n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    # Informa√ß√µes adicionais\n",
    "    f.write(\"---\\n\\n\")\n",
    "    f.write(\"## Formato dos Arquivos\\n\\n\")\n",
    "    f.write(\"Cada arquivo cont√©m:\\n\\n\")\n",
    "    f.write(\"1. **DESCRIBE FORMATTED** - Estrutura completa da tabela\\n\")\n",
    "    f.write(\"2. **SELECT LIMIT 10** - Amostra de 10 registros\\n\\n\")\n",
    "\n",
    "    f.write(\"## Como Regenerar\\n\\n\")\n",
    "    f.write(\"Para regenerar todos os schemas, execute o notebook:\\n\\n\")\n",
    "    f.write(\"`Gerar_Data_Schemas.ipynb`\\n\")\n",
    "\n",
    "print(f\"‚úÖ √çndice gerado: {indice_path}\")\n",
    "print(f\"üìÅ Arquivos dispon√≠veis em: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Listar Arquivos Gerados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listar todos os arquivos gerados no diret√≥rio de sa√≠da\n",
    "\n",
    "import os\n",
    "\n",
    "arquivos = sorted(os.listdir(OUTPUT_DIR))\n",
    "\n",
    "print(f\"\\nüìÅ Arquivos em {OUTPUT_DIR}:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "schemas = [f for f in arquivos if f.endswith('_schema.txt')]\n",
    "erros = [f for f in arquivos if f.startswith('ERRO_')]\n",
    "outros = [f for f in arquivos if f not in schemas and f not in erros]\n",
    "\n",
    "print(f\"\\n‚úÖ Schemas gerados ({len(schemas)}):\")\n",
    "for arquivo in schemas:\n",
    "    tamanho = os.path.getsize(os.path.join(OUTPUT_DIR, arquivo))\n",
    "    print(f\"   - {arquivo} ({tamanho:,} bytes)\")\n",
    "\n",
    "if erros:\n",
    "    print(f\"\\n‚ùå Arquivos de erro ({len(erros)}):\")\n",
    "    for arquivo in erros:\n",
    "        print(f\"   - {arquivo}\")\n",
    "\n",
    "if outros:\n",
    "    print(f\"\\n‚ÑπÔ∏è  Outros arquivos ({len(outros)}):\")\n",
    "    for arquivo in outros:\n",
    "        print(f\"   - {arquivo}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Conclu√≠do!\n",
    "\n",
    "Os schemas foram gerados com sucesso no diret√≥rio `./data-schemas/`.\n",
    "\n",
    "### Pr√≥ximos passos:\n",
    "\n",
    "1. Revise os arquivos gerados em `./data-schemas/`\n",
    "2. Verifique se h√° arquivos de erro e investigue as causas\n",
    "3. Use os schemas para documenta√ß√£o do projeto\n",
    "\n",
    "### Estrutura gerada:\n",
    "\n",
    "```\n",
    "data-schemas/\n",
    "‚îú‚îÄ‚îÄ README.md                                    # √çndice de todos os schemas\n",
    "‚îú‚îÄ‚îÄ nfce_schema.txt                             # Schema da tabela nfce.nfce\n",
    "‚îú‚îÄ‚îÄ argos_cnpj_schema.txt                       # Schema da tabela niat.argos_cnpj\n",
    "‚îú‚îÄ‚îÄ tabela_niat_schema.txt                      # Schema da tabela niat.tabela_niat\n",
    "‚îú‚îÄ‚îÄ vw_ods_contrib_schema.txt                   # Schema da view usr_sat_ods.vw_ods_contrib\n",
    "‚îú‚îÄ‚îÄ argos_nfce_base_extraida_schema.txt         # Schema da tabela intermedi√°ria\n",
    "‚îú‚îÄ‚îÄ argos_nfce_periodo_base_schema.txt          # Schema da tabela intermedi√°ria\n",
    "‚îú‚îÄ‚îÄ argos_medias_historicas_produto_schema.txt  # Schema da tabela intermedi√°ria\n",
    "‚îú‚îÄ‚îÄ argos_mudanca_comportamento_schema.txt      # Schema da tabela intermedi√°ria\n",
    "‚îî‚îÄ‚îÄ argos_vw_evolucao_nfce_schema.txt          # Schema da view principal ‚≠ê\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
